{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Rapport du Projet : Reconnaissance d'Entités Nommées (NER)**\n",
    "### **Auteur BONKOUNGOU Benewende Pierre**\n",
    "### **Tel:** 73 87 73 42\n",
    "\n",
    "---\n",
    "### **1. Introduction**\n",
    "Ce projet vise à développer un modèle de **Reconnaissance d'Entités Nommées (NER)** spécifique au domaine de l'intelligence artificielle (IA) en utilisant la bibliothèque **spaCy**. Le modèle est capable de détecter des entités telles que des technologies, des concepts, des outils et des acronymes spécifiques à l'IA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### **2. Objectifs**\n",
    "- **Collecter et prétraiter** un corpus de textes sur l'IA.\n",
    "- **Développer des motifs regex** pour détecter des entités simples.\n",
    "- **Annoter manuellement** les données pour entraîner un modèle spaCy personnalisé.\n",
    "- **Évaluer et améliorer** le modèle.\n",
    "- **Déployer une interface Streamlit** pour tester le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### **3. Étapes du Projet**\n",
    "\n",
    "#### **3.1. Collecte des Données**\n",
    "- **Source des données** : Articles, publications et rapports sur l'IA.\n",
    "- **Exemple de corpus** : Textes contenant des termes comme \"Machine Learning\", \"Deep Learning\", \"Neural Networks\", etc.\n",
    "\n",
    "#### **3.2. Prétraitement des Données**\n",
    "- **Nettoyage du texte** : Suppression des stopwords, lemmatisation, etc.\n",
    "#### **Code** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Chargement du modèle de langue français de spaCy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Nettoie et prétraite le texte.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    # Suppressions des stopwords et des ponctuations, et lemmatisation\n",
    "    cleaned_text = \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "#### **3.3. Développement de Motifs Regex**\n",
    "- **Exemples de motifs** :\n",
    "  - Dates : `\\d{2}/\\d{2}/\\d{4}`\n",
    "  - Acronymes : `[A-Z]{2,}`\n",
    "#### **Code** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Motifs regex pour détecter des dates et des acronymes\n",
    "regex_patterns = {\n",
    "    \"DATE\": r\"\\d{2}/\\d{2}/\\d{4}\",  # Dates au format JJ/MM/AAAA\n",
    "    \"ACRONYM\": r\"[A-Z]{2,}\",       # Acronymes en majuscules\n",
    "}\n",
    "\n",
    "def detect_entities(text, pattern_type):\n",
    "    \"\"\"\n",
    "    Détection des entités dans un texte en utilisant un motif regex.\n",
    "    \"\"\"\n",
    "    pattern = regex_patterns.get(pattern_type)\n",
    "    if pattern:\n",
    "        return re.findall(pattern, text)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "#### **3.4. Annotation Manuelle des Données**\n",
    "- **Entités annotées** : Technologies, concepts, outils, acronymes.\n",
    "- **Exemple d'annotation** :\n",
    " ```json\n",
    "  {\"label\": \"TECHNOLOGY\", \"pattern\": \"Machine Learning\"}\n",
    "  ```\n",
    "\n",
    "---\n",
    "#### **3.5. Entraînement du Modèle**\n",
    "- **Script d'entraînement** :\n",
    "\n",
    "#### **Code** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle personnalisé entraîné et sauvegardé avec succès !\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "# Charger le modèle de langue français de spaCy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Ajouter un EntityRuler au pipeline\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")  # Utiliser le nom du composant\n",
    "\n",
    "# Ajouter des motifs personnalisés\n",
    "patterns = [\n",
    "    # Technologies\n",
    "    {\"label\": \"TECHNOLOGY\", \"pattern\": \"Machine Learning\"},\n",
    "    {\"label\": \"TECHNOLOGY\", \"pattern\": \"Deep Learning\"},\n",
    "    {\"label\": \"TECHNOLOGY\", \"pattern\": \"Neural Networks\"},\n",
    "    {\"label\": \"TECHNOLOGY\", \"pattern\": \"Artificial Intelligence\"},\n",
    "    {\"label\": \"TECHNOLOGY\", \"pattern\": \"Natural Language Processing\"},\n",
    "    {\"label\": \"TECHNOLOGY\", \"pattern\": \"Computer Vision\"},\n",
    "    {\"label\": \"TECHNOLOGY\", \"pattern\": \"Reinforcement Learning\"},\n",
    "\n",
    "    # Concepts\n",
    "    {\"label\": \"CONCEPT\", \"pattern\": \"Supervised Learning\"},\n",
    "    {\"label\": \"CONCEPT\", \"pattern\": \"Unsupervised Learning\"},\n",
    "    {\"label\": \"CONCEPT\", \"pattern\": \"Semi-Supervised Learning\"},\n",
    "    {\"label\": \"CONCEPT\", \"pattern\": \"Transfer Learning\"},\n",
    "    {\"label\": \"CONCEPT\", \"pattern\": \"Generative Adversarial Networks\"},\n",
    "    {\"label\": \"CONCEPT\", \"pattern\": \"Convolutional Neural Networks\"},\n",
    "    {\"label\": \"CONCEPT\", \"pattern\": \"Recurrent Neural Networks\"},\n",
    "\n",
    "    # Outils et frameworks\n",
    "    {\"label\": \"TOOL\", \"pattern\": \"TensorFlow\"},\n",
    "    {\"label\": \"TOOL\", \"pattern\": \"PyTorch\"},\n",
    "    {\"label\": \"TOOL\", \"pattern\": \"Keras\"},\n",
    "    {\"label\": \"TOOL\", \"pattern\": \"Scikit-learn\"},\n",
    "    {\"label\": \"TOOL\", \"pattern\": \"OpenCV\"},\n",
    "    {\"label\": \"TOOL\", \"pattern\": \"NLTK\"},\n",
    "    {\"label\": \"TOOL\", \"pattern\": \"SpaCy\"},\n",
    "\n",
    "    # Acronymes\n",
    "    {\"label\": \"ACRONYM\", \"pattern\": \"AI\"},\n",
    "    {\"label\": \"ACRONYM\", \"pattern\": \"ML\"},\n",
    "    {\"label\": \"ACRONYM\", \"pattern\": \"DL\"},\n",
    "    {\"label\": \"ACRONYM\", \"pattern\": \"NLP\"},\n",
    "    {\"label\": \"ACRONYM\", \"pattern\": \"CV\"},\n",
    "    {\"label\": \"ACRONYM\", \"pattern\": \"GAN\"},\n",
    "    {\"label\": \"ACRONYM\", \"pattern\": \"CNN\"},\n",
    "    {\"label\": \"ACRONYM\", \"pattern\": \"RNN\"},\n",
    "]\n",
    "\n",
    "# Ajouter les motifs au ruler\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "# Sauvegarder le modèle personnalisé\n",
    "nlp.to_disk(\"models/custom_ner_model\")\n",
    "\n",
    "print(\"Modèle personnalisé entraîné et sauvegardé avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "#### **3.6. Évaluation du Modèle**\n",
    "- **Métriques** : Précision, rappel, F1-score.\n",
    "#### **Code** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_model\u001b[39m(y_true, y_pred):\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m        y_true (array-like): Les étiquettes réelles (vraies classes).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m        None: Affiche le rapport de classification.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benew\\NER-Projet-IA\\.venv\\Lib\\site-packages\\sklearn\\__init__.py:73\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     __check_build,\n\u001b[0;32m     71\u001b[0m     _distributor_init,\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     76\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\benew\\NER-Projet-IA\\.venv\\Lib\\site-packages\\sklearn\\base.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_set_output\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _SetOutputMixin\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     ClassifierTags,\n\u001b[0;32m     25\u001b[0m     RegressorTags,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     get_tags,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n",
      "File \u001b[1;32mc:\\Users\\benew\\NER-Projet-IA\\.venv\\Lib\\site-packages\\sklearn\\utils\\__init__.py:42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscovery\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m all_estimators\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextmath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m safe_sqr\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     44\u001b[0m     as_float_array,\n\u001b[0;32m     45\u001b[0m     assert_all_finite,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     indexable,\n\u001b[0;32m     54\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# TODO(1.7): remove parallel_backend and register_parallel_backend\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benew\\NER-Projet-IA\\.venv\\Lib\\site-packages\\sklearn\\utils\\murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y_true (array-like): Les étiquettes réelles (vraies classes).\n",
    "        y_pred (array-like): Les étiquettes prédites par le modèle.\n",
    "\n",
    "    Returns:\n",
    "        None: Affiche le rapport de classification.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Générer et afficher le rapport de classification\n",
    "        report = classification_report(y_true, y_pred)\n",
    "        print(\"Rapport de classification :\")\n",
    "        print(report)\n",
    "    except Exception as e:\n",
    "        # Gérer les erreurs potentielles (par exemple, si les entrées sont invalides)\n",
    "        print(f\"Une erreur s'est produite lors de l'évaluation du modèle : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### **3.7. Déploiement de l'Application Streamlit**\n",
    "##### **Fonctionnalités** :\n",
    "  - Saisie manuelle de texte.\n",
    "  - Chargement de fichiers texte.\n",
    "  - Affichage des entités détectées.\n",
    "\n",
    "##### **Code** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 20:19:10.257 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\benew\\NER-Projet-IA\\.venv\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import spacy\n",
    "\n",
    "# Titre de l'application\n",
    "st.title(\"Reconnaissance d'Entités Nommées (NER)\")\n",
    "\n",
    "# Charger le modèle spaCy personnalisé\n",
    "nlp = spacy.load(\"models/custom_ner_model\")\n",
    "\n",
    "# Option pour saisir du texte manuellement\n",
    "st.header(\"Saisir du texte\")\n",
    "user_input = st.text_area(\"Entrez votre texte ici\")\n",
    "\n",
    "# Option pour charger un fichier texte\n",
    "st.header(\"Charger un fichier texte\")\n",
    "uploaded_file = st.file_uploader(\"Choisissez un fichier texte\", type=[\"txt\"])\n",
    "\n",
    "# Bouton pour lancer l'analyse\n",
    "if st.button(\"Analyser\"):\n",
    "    if user_input or uploaded_file:\n",
    "        # Si un fichier est chargé, lire son contenu\n",
    "        if uploaded_file:\n",
    "            text = uploaded_file.read().decode(\"utf-8\")\n",
    "        else:\n",
    "            text = user_input\n",
    "\n",
    "        # Analyser le texte avec le modèle spaCy\n",
    "        doc = nlp(text)\n",
    "\n",
    "        # Afficher les entités détectées\n",
    "        st.header(\"Entités détectées\")\n",
    "        for ent in doc.ents:\n",
    "            st.write(f\"**Entité** : {ent.text}, **Label** : {ent.label_}\")\n",
    "\n",
    "        # Afficher le texte annoté\n",
    "        st.header(\"Texte annoté\")\n",
    "        st.write(doc.ents)\n",
    "    else:\n",
    "        st.warning(\"Veuillez saisir du texte ou charger un fichier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **4. Résultats**\n",
    "\n",
    "#### **4.1. Entités Détectées**\n",
    "Voici un exemple de sortie de l'application Streamlit :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Résultats des Entités Détectées](data/screenshots/output_results.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### **4.2. Texte Annoté**\n",
    "Le texte annoté montre les entités détectées avec leurs labels.\n",
    "![Code de l'Application](data/screenshots/output2_annoted.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### **4.3. Interface Streamlit**\n",
    "![Capture d'écran de l'application Streamlit](data/screenshots/streamlit_interface1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Capture d'écran de l'application Streamlit](data/screenshots/streamlit_interface2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Capture d'écran de l'application Streamlit](data/screenshots/streamlit_interface3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.4. Dépôt GitHub**\n",
    "Le code source du projet est disponible sur GitHub :  \n",
    "[Lien vers le dépôt GitHub](https://github.com/VirtuelsDev/NER-Projet-IA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### **4.5. Conclusion**\n",
    "Ce projet a permis de développer un modèle de NER spécifique au domaine de l'IA. Le modèle est capable de détecter des entités pertinentes avec une bonne précision. L'application Streamlit offre une interface conviviale pour tester le modèle.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.6. Prochaines Étapes**\n",
    "- **Améliorer le modèle** : Ajouter plus de motifs personnalisés et entraîner sur un corpus plus large.\n",
    "- **Déployer sur le cloud** : Héberger l'application sur AWS, Google Cloud ou Azure.\n",
    "- **Ajouter des fonctionnalités** : Analyse des émotions, visualisation des résultats, etc.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.7. Fichier Jupyter Notebook**\n",
    "Le fichier Jupyter Notebook (`Projet1_NerApp_Bonkoungou.ipynb`) contient :\n",
    "- Les captures d'écran.\n",
    "- Le lien vers le dépôt GitHub.\n",
    "\n",
    "Le fichier Jupyter Notebook (`Projet1_NerApp_Bonkoungou.ipynb`) est disponible dans le dépôt GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.8. Instructions pour Exécuter le Projet**\n",
    "1. **Cloner le dépôt GitHub** :\n",
    "   ```bash\n",
    "   git clone https://github.com/VirtuelsDev/NER-Projet-IA.git\n",
    "   ```\n",
    "2. **Installer les dépendances** :\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "3. **Télécharger le modèle de langue française** :\n",
    "   ```bash\n",
    "   python -m spacy download fr_core_news_sm\n",
    "   ```\n",
    "4. **Entraîner le Modèle**\n",
    "   ```bash\n",
    "   python src/train_ner_model.py\n",
    "   ```\n",
    "\n",
    "5. **Exécuter l'application Streamlit** :\n",
    "   ```bash\n",
    "   streamlit run src/app.py\n",
    "   ```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
